{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   person  position            6            7            8            9  \\\n",
      "0       1        17   795.910156   849.388000   890.166809   912.882263   \n",
      "1       1        17   798.279419   843.614258   868.484314   895.013977   \n",
      "2       1        17  1064.543091  1086.945312  1105.320312  1135.975342   \n",
      "3       1        17  1060.771362  1092.156128  1112.137573  1130.086670   \n",
      "4       1        17  1329.939087  1409.457397  1416.469604  1432.482056   \n",
      "\n",
      "            10           11           12           13  ...        241  \\\n",
      "0   946.926086   979.547363  1059.871704  1146.253052  ...  52.201534   \n",
      "1   921.195984   935.745667  1021.312866  1114.450928  ...  33.526108   \n",
      "2  1170.029907  1180.800171  1267.976318  1369.742310  ...  47.539455   \n",
      "3  1138.223999  1126.414673  1193.649902  1277.542969  ...  26.870058   \n",
      "4  1445.448364  1401.856567  1508.621948  1599.805298  ...  51.156624   \n",
      "\n",
      "         242        243        244        245         246         247  \\\n",
      "0  41.773197  24.515301  16.552946  35.227829   36.400551   50.209560   \n",
      "1  27.459061  43.382023  33.301651  64.327286   26.570660   12.165525   \n",
      "2  14.560220  39.560081  56.142673  51.971146   22.627417   24.020824   \n",
      "3  44.384682  15.000000  44.944408  60.539242   60.671246   19.697716   \n",
      "4  74.946648  55.081757  56.364883  22.360680  105.261581  114.004387   \n",
      "\n",
      "         248        249         250  \n",
      "0  35.468296  41.036568   64.884514  \n",
      "1  37.013512  64.195015   16.124516  \n",
      "2  20.223749  34.058773   41.109608  \n",
      "3  89.498604  39.623226  128.949600  \n",
      "4  71.168816  33.120991   60.008331  \n",
      "\n",
      "[5 rows x 236 columns]\n"
     ]
    }
   ],
   "source": [
    "data_path = \"../data/combined/\"\n",
    "data_file = \"amplitude_csi_dataframe.pkl\"\n",
    "\n",
    "DISCRETE_VARIABLES = [\"person\"]\n",
    "TARGET_VARIABLE = \"position\"\n",
    "STATE = 42\n",
    "\n",
    "data_df: pd.DataFrame = pd.read_pickle(data_path + data_file)\n",
    "\n",
    "# Convert all column names to strings\n",
    "data_df.columns = data_df.columns.astype(str)\n",
    "\n",
    "print(data_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[44.          0.38642046  0.29976055 ...  2.169638    2.7544522\n",
      "  -0.07609867]\n",
      " [26.         -0.69760364 -0.6823467  ... -0.5210067  -0.4048676\n",
      "  -0.7114199 ]\n",
      " [52.         -0.6339469  -0.64925706 ... -0.5595189  -0.6062821\n",
      "   0.19943404]\n",
      " [ 8.         -0.88174653 -0.9246833  ... -1.0051556  -0.37353423\n",
      "  -0.69077873]\n",
      " [49.          1.1035314   1.0955558  ... -0.37058067 -0.4393156\n",
      "   0.4879667 ]]\n",
      "1559868    17\n",
      "903800     12\n",
      "1865988     8\n",
      "277030      7\n",
      "1732226    13\n",
      "Name: position, dtype: uint8\n",
      "[[46.         -0.21375568 -0.2730182  ... -0.98993266 -0.86679655\n",
      "  -0.8598902 ]\n",
      " [10.         -1.2045823  -1.1377039  ... -0.75811535  0.9736769\n",
      "  -0.10447231]\n",
      " [33.         -1.7443719  -1.7738211  ... -0.71422815 -0.5750575\n",
      "  -0.17337221]\n",
      " [56.         -1.4034363  -1.4370869  ... -0.5831633  -0.74591374\n",
      "  -0.72425234]\n",
      " [32.         -1.1189996  -1.1041296  ... -0.22216593 -0.5311101\n",
      "  -0.33968678]]\n",
      "1625434    13\n",
      "323710     10\n",
      "1151379     0\n",
      "1993553     1\n",
      "1135407     3\n",
      "Name: position, dtype: uint8\n"
     ]
    }
   ],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "numeric_transformer = Pipeline(\n",
    "    steps=[(\"imputer\", SimpleImputer(strategy=\"median\")), (\"scaler\", StandardScaler())]\n",
    ")\n",
    "\n",
    "numerical_columns = [\n",
    "    col\n",
    "    for col in data_df.columns\n",
    "    if col not in DISCRETE_VARIABLES and col != TARGET_VARIABLE\n",
    "]\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"cat\", \"passthrough\", DISCRETE_VARIABLES),\n",
    "        (\"num\", numeric_transformer, numerical_columns),\n",
    "    ]\n",
    ")\n",
    "\n",
    "X = data_df.drop(columns=[TARGET_VARIABLE])\n",
    "X = preprocessor.fit_transform(X)\n",
    "y = data_df[TARGET_VARIABLE]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=STATE\n",
    ")\n",
    "\n",
    "print(X_train[:5])\n",
    "print(y_train[:5])\n",
    "print(X_test[:5])\n",
    "print(y_test[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved to ../data/train_test_split/\n"
     ]
    }
   ],
   "source": [
    "save_path = \"../data/train_test_split/\"\n",
    "\n",
    "def save_pkl(obj: object, path: str) -> None:\n",
    "    with open(path, \"wb\") as f:\n",
    "        pd.to_pickle(obj, f)\n",
    "\n",
    "save_pkl(X_train, save_path + \"X_train.pkl\")\n",
    "save_pkl(y_train, save_path + \"y_train.pkl\")\n",
    "save_pkl(X_test, save_path + \"X_test.pkl\")\n",
    "save_pkl(y_test, save_path + \"y_test.pkl\")\n",
    "\n",
    "print(\"Data saved to\", save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved to ../data/train_test_split/\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Convert the data to PyTorch tensors\n",
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train.values, dtype=torch.long)\n",
    "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test.values, dtype=torch.long)\n",
    "\n",
    "torch.save(X_train_tensor, save_path + \"X_train.pt\")\n",
    "torch.save(y_train_tensor, save_path + \"y_train.pt\")\n",
    "torch.save(X_test_tensor, save_path + \"X_test.pt\")\n",
    "torch.save(y_test_tensor, save_path + \"y_test.pt\")\n",
    "\n",
    "print(\"Data saved to\", save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gurgel\\AppData\\Local\\Temp\\ipykernel_5548\\3658637564.py:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  train_X = torch.load(save_path + \"X_train.pt\")\n",
      "C:\\Users\\gurgel\\AppData\\Local\\Temp\\ipykernel_5548\\3658637564.py:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  train_y = torch.load(save_path + \"y_train.pt\")\n",
      "C:\\Users\\gurgel\\AppData\\Local\\Temp\\ipykernel_5548\\3658637564.py:3: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  test_X = torch.load(save_path + \"X_test.pt\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[44.0000,  0.3864,  0.2998,  ...,  2.1696,  2.7545, -0.0761],\n",
      "        [26.0000, -0.6976, -0.6823,  ..., -0.5210, -0.4049, -0.7114],\n",
      "        [52.0000, -0.6339, -0.6493,  ..., -0.5595, -0.6063,  0.1994],\n",
      "        [ 8.0000, -0.8817, -0.9247,  ..., -1.0052, -0.3735, -0.6908],\n",
      "        [49.0000,  1.1035,  1.0956,  ..., -0.3706, -0.4393,  0.4880]])\n",
      "tensor([17, 12,  8,  7, 13])\n",
      "tensor([[46.0000, -0.2138, -0.2730,  ..., -0.9899, -0.8668, -0.8599],\n",
      "        [10.0000, -1.2046, -1.1377,  ..., -0.7581,  0.9737, -0.1045],\n",
      "        [33.0000, -1.7444, -1.7738,  ..., -0.7142, -0.5751, -0.1734],\n",
      "        [56.0000, -1.4034, -1.4371,  ..., -0.5832, -0.7459, -0.7243],\n",
      "        [32.0000, -1.1190, -1.1041,  ..., -0.2222, -0.5311, -0.3397]])\n",
      "tensor([13, 10,  0,  1,  3])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gurgel\\AppData\\Local\\Temp\\ipykernel_5548\\3658637564.py:4: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  test_y = torch.load(save_path + \"y_test.pt\")\n"
     ]
    }
   ],
   "source": [
    "train_X = torch.load(save_path + \"X_train.pt\")\n",
    "train_y = torch.load(save_path + \"y_train.pt\")\n",
    "test_X = torch.load(save_path + \"X_test.pt\")\n",
    "test_y = torch.load(save_path + \"y_test.pt\")\n",
    "\n",
    "print(train_X[:5])\n",
    "print(train_y[:5])\n",
    "print(test_X[:5])\n",
    "print(test_y[:5])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
